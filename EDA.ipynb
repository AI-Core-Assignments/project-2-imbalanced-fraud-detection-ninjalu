{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the EDA notebook for the credit card fraud detection project\n",
    "### Table of contents:\n",
    "1. Project overview\n",
    "2. First look at the data\n",
    "3. Plots labels vs features\n",
    "4. Explore basic logistic model\n",
    "5. Sum up with preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Project overview\n",
    "This project aim to identify whether a credit card transaction is fraudulent or not. <br>\n",
    "The data comes from a Kaggle competition: https://www.kaggle.com/mlg-ulb/creditcardfraud <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. First look at the data\n",
    "Some information from the tast \n",
    "The data is highly unbalanced only 492 out of 284,807 samples are fraudulent. <br>\n",
    "Feature V1-28 are anonymous and uninterpretable principal components. <br>\n",
    "Time and Amound have not been transformed. <br>\n",
    "Time contains the number of seconds elapsed between each transaction and the first transaction in the dataset.<br>\n",
    "Amount refers to the transaction amount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('creditcard_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 199,364 data points, with no missing value.<br>\n",
    "As we can see Time needs to be converted to datetimedelta object, and Class into category. <br>\n",
    "We will transform Time into datetime seconds for now, and explore whether hours, minutes later. <br>\n",
    "This dataset time span about 2 days (172792/86400)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Time into datetime delta; Class into category and sort by Time\n",
    "import datetime\n",
    "df_train['timedelta'] = df_train['Time'].apply(lambda x: datetime.timedelta(seconds=x))\n",
    "df_train['fraud'] = df_train['Class'].astype('category')\n",
    "df_train.sort_values('Time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fraudulent frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_pct = df_train['fraud'].value_counts()[1]/len(df_train)*100\n",
    "print('{}% of the transactios are fraudulent'.format(fraudulent_pct.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time vs Fraudulent Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['min'] = (df_train['Time']//60).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['hour'] = (df_train['Time']//3600).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# df_train['fraud_by_hr'] = df_train.groupby('hour').mean()['Class']\n",
    "# px.bar(x=df_train.groupby('hour').mean().index, y=df_train.groupby('hour').mean()['Class'], \n",
    "#         title='Average of fraudulent transactions by hour', \n",
    "#         labels={'x': 'Hour', 'y':  'Average fraudulant transactions'})\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(15,10))\n",
    "fig = sns.barplot(x='hour', y='Class', data=df_train)\n",
    "fig.set(xlabel='Hour', ylabel='Average fraud count', title='Average fraud count by hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between 2-7 hours after hour 0 each day, there are spikes of fraudulent activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.line(x=df_train.groupby('min').mean().index, y=df_train.groupby('min').mean()['Class'], \n",
    "#         title='Average of fraudulent transactions by minute', \n",
    "#         labels={'x': 'Minute', 'y':  'Average fraudulant transactions'})\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "fig = sns.barplot(x='min', y='Class', data=df_train)\n",
    "fig.set(xlabel='Minute', ylabel='Average fraud count', title='Average fraud count by minute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a similar pattern by minute, and some day to day differences too. However, will not be able to model day to day differences due to lack of data. <br>\n",
    "It seems that the increased fraud activity might be focused around early hours, and not just because of outliers<br>\n",
    "Because there is a periodic pattern, we are going to transform Time, min and hour, and squeeze the data into one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sec'] = [second if second<=86400 else second-86400 for second in list(df_train['Time'])]\n",
    "df_train['min'] = [minute if minute<=1440 else minute-1440 for minute in list(df_train['min'])]\n",
    "df_train['hour'] = [hour if hour<=23 else hour-24 for hour in list(df_train['hour'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.bar(x=df_train.groupby('hour').mean().index, y=df_train.groupby('hour').mean()['Class'], \n",
    "#         title='Average of fraudulent transactions by hour', \n",
    "#         labels={'x': 'Hour', 'y':  'Average fraudulant transactions'})\n",
    "\n",
    "# Plot average fraud count by hour again:\\\n",
    "plt.figure(figsize=(15,10))\n",
    "fig = sns.barplot(x='hour', y='Class', data=df_train)\n",
    "fig.set(xlabel='Hour', ylabel='Average fraud count', title='Average fraud count by hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is definitely a peak in fraudulent transacations. Do we consider isolating those hours? Or there are two types of fraud, one constant cross all hours and another happens at the early hours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amount vs Fraudulent Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('fraud').mean()['Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraudulent transaction is on average 44% more than nonfraudulent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# hours = list(set(df_train['hour'].astype('str')))\n",
    "# fraudulent_amount_by_hour = df_train[df_train['fraud']==1].groupby('hour').mean()['Amount']\n",
    "# genuine_amount_by_hour = df_train[df_train['fraud']==0].groupby('hour').mean()['Amount']\n",
    "# fig = go.Figure(data=[\n",
    "#     go.Bar(name='Fraudulent', x=hours, y=fraudulent_amount_by_hour),\n",
    "#     go.Bar(name='Genuine', x=hours, y=genuine_amount_by_hour)\n",
    "# ])\n",
    "# fig.update_layout(title='Average raudulent and genuine ransaction amount by hour', barmode='group',\n",
    "#                  yaxis=dict(title='Average transaction amount'),\n",
    "#                  xaxis=dict(title='Hours'),\n",
    "#                  hovermode='x unified')\n",
    "# fig.show()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "fig = sns.barplot(x='hour', y='Amount', hue='fraud', data=df_train)\n",
    "fig.set(xlabel='Hour', ylabel='Average transaction amount', title='Average transation amount by hour: fraud vs genuine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genuine transaction amount is very constant, whereas fraud transactions amount varies hugely, not only between themselves (huge confidence intervals), but also between different hours. <br>\n",
    "Because of the fact that the fraudulent amount varies hugely, we need to be very cautious excluding any outliers in the data, unless justified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plotly.subplots import make_subplots\n",
    "# fig = make_subplots(rows=2, cols=1, subplot_titles=['Distribution of amount: fraudulent', 'Distribution of amount: genuine'])\n",
    "# fig.add_trace(go.Histogram(\n",
    "#     x=df_train[df_train['fraud']==1]['Amount'], nbinsx=500\n",
    "# ), row=1, col=1)\n",
    "# fig.add_trace(go.Histogram(\n",
    "#     x=df_train[df_train['fraud']==0]['Amount'], nbinsx=500\n",
    "# ), row=2, col=1)\n",
    "# fig.update_layout(showlegend=False)\n",
    "# fig.show()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "fig = sns.boxplot(data=df_train, x='fraud', y='Amount')\n",
    "fig.set(title='Amount distribution: fraud vs genuine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like genuine transaction amounts vary more than fraudulent ones. Let's zoom into Amount less than 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "fig = sns.boxplot(data=df_train, x='fraud', y='Amount')\n",
    "fig.set(title='Amount distribution: fraud vs genuine', ylim=(0,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genuine transactions have higher medium amount, but lower upper fence. Fraudulent transaction amounts cluster more just above 0. Let's see it in histogram again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "fig = sns.displot(df_train[df_train['fraud']==1], x='Amount', height=8, aspect=2)\n",
    "fig.set(title='Amount distribution: fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "fig = sns.displot(df_train[df_train['fraud']==0], x='Amount', height=5, aspect=3)\n",
    "fig.set(title='Amount distribution: genuine', ylim=(0,10000), xlim=(0,2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Zoom in to amount range from 0 to 500\n",
    "# from plotly.subplots import make_subplots\n",
    "# fig = make_subplots(rows=2, cols=1, subplot_titles=['Distribution of amount: fraudulent', 'Distribution of amount: genuine'])\n",
    "# fig.add_trace(go.Histogram(\n",
    "#     x=df_train[df_train['fraud']==1]['Amount'], nbinsx=500\n",
    "# ), row=1, col=1)\n",
    "# fig.add_trace(go.Histogram(\n",
    "#     x=df_train[df_train['fraud']==0]['Amount'], nbinsx=5000\n",
    "# ), row=2, col=1)\n",
    "# fig.update_layout(showlegend=False)\n",
    "# fig.update_xaxes(title_text='Transaction amount', range=[0,500], row=1, col=1)\n",
    "# fig.update_xaxes(title_text='Transaction amount', range=[0,500], row=2, col=1)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be two clusters of fraudulent transaction amounts, one around 0, another around 100. Fraudulent transaction amount rarely go beyond 500. <br>\n",
    "Does it mean two different patterns of fraudulent activities, or it's noise due to the day to day variance? <br>\n",
    "There is a mean difference between fraudulent and genuine transaction amount. Let's formally test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "fraud_amount = df_train[df_train['fraud']==1]['Amount']\n",
    "genuine_amount = df_train[df_train['fraud']==0]['Amount']\n",
    "ttest_ind(fraud_amount, genuine_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant difference between the mean amount from fraudulent transactions to genuine transactions. But we need to be careful, because although the average amount is higher for fraudulent transactions, we need to think about the implication of identifying big amount as fraudulent, because clearly there are a huge number of genuine high-value transactions. Maybe amount combining with other features will be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1-28 vs fraudulence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at V1-28. Bellow we plot out V1-28 in searborn pairplot. In the diagnal line is the distribution of each V feature and the rest are scatter plots of one V feature against another. <br>\n",
    "Blue represent genuine transaction data points. Orange represent fraudulent transaction data points.<br>\n",
    "(Pairplot has been broken down into 7 parts so it takes less time to run.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unkwn_features = ['V{}'.format(n+1) for n in range(0,28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# rows = (len(unkwn_features)//2)\n",
    "# cols = 2\n",
    "# subplot_titles = tuple(var+' distribution' for var in unkwn_features)\n",
    "# fig = make_subplots(rows=rows, cols=cols, subplot_titles=subplot_titles)\n",
    "\n",
    "# for i, feature in enumerate(unkwn_features):\n",
    "#     row = (i//cols)+1\n",
    "#     col = (i%cols)+1\n",
    "    \n",
    "#     fig.add_trace(go.Histogram(\n",
    "#         x=df_train[feature]\n",
    "#     ), row=row, col=col)\n",
    "\n",
    "# fig.update_layout(height=4000, showlegend=False)\n",
    "# fig.show()\n",
    "from IPython.display import Image\n",
    "nplots = 7\n",
    "for i in range(nplots):\n",
    "    df = df_train[unkwn_features[i*4: (i+1)*4]+['fraud']]\n",
    "    fig = sns.pairplot(df, hue='fraud')\n",
    "    fig.savefig(\"pairplot{}.png\".format(i+1))\n",
    "    plt.clf() # Clean parirplot figure from sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='pairplot1.png') # Show pairplot as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='pairplot2.png') # Show pairplot as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='pairplot3.png') # Show pairplot as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='pairplot4.png') # Show pairplot as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='pairplot5.png') # Show pairplot as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='pairplot6.png') # Show pairplot as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='pairplot7.png') # Show pairplot as image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1-28 are all continuous standardised features with a mean of 0. <br>\n",
    "The features for fraudulent transactions seem to have more contant distribution, often near or beyong one tail of genuine transaction features distributions (normal).<br>\n",
    "There is multicoliniarity present amongst V features. Fraudulent transactions sometimes sit on one extreme tail of the correlation (e.g. V10:V9), sometimes sit outside of the correlation/form a different correlation (e.g. V5:V7)<br>\n",
    "Promising features include: V1-20 seem to be more promising. Harder to tell from V21-28, but we will look at these in detail later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap outlining correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df_train['hour'] = df_train['hour'].astype('category')\n",
    "df_train = pd.get_dummies(df_train, drop_first=True)\n",
    "scaler = MinMaxScaler()\n",
    "df_train['Amount'] = np.squeeze(scaler.fit_transform(np.array(df_train['Amount']).reshape(-1,1)))\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns={'fraud_1':'fraud'}, inplace=True)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lst = ['Class', 'Amount'] + unkwn_features + ['hour_{}'.format(i) for i in range(1,24)]\n",
    "df_hm = pd.DataFrame(df_train[features_lst].corr()['Class'].sort_values(ascending=False))\n",
    "plt.figure(figsize=(10,20))\n",
    "sns.heatmap(df_hm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most positively related to fraud transactions: V11, V4, V2, V21, hour_2, V19, hour_4, V20, V27, V8 <br>\n",
    "The most negatively related to fraud transactions: V17, V14, V12, V10, V16, V3, V7,V18, V1, V9, V5, V6 <br>\n",
    "The negative correlations seems to be stronger than the positive ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE** Because we have a very unbalanced data, feature importance drawn from the above heatmap might not be very accurate. Here we try to resolve this problem using Synthetic Minority Oversampling Technique, SMOTE, and Random Under Sampling. <br>\n",
    "Ref: https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/ <br>\n",
    "We will: 1. over sample fraud transactions to be 10% of the genuine transactions. 2. Then under sample the genuine transactions so the numbers match with fraud transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[features_lst].drop('Class', axis=1)\n",
    "y = df_train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "over = SMOTE(random_state=42, sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X, y = pipeline.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put y back into the data frame for heatmap\n",
    "X['fraud'] = y\n",
    "df_hm = pd.DataFrame(X.corr()['fraud'].sort_values(ascending=False))\n",
    "plt.figure(figsize=(10,20))\n",
    "sns.heatmap(df_hm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important features didn't seem to change, but the correlation magnitude have increased and order changed. <br>\n",
    "We are not picking out the most correlated features here, because we want to use a basic logistic model to help reduce the dimensionality and further feature engineering if need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35,35))\n",
    "sns.heatmap(X.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is very strong multicolinearity amongst V1-18. We assume the anonamous features have some actual meanings, hence useful to keep them as they are for interpretation. Therefore, we do not to represent them with less features using PCA for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Basic Logistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a basic logistic model to:\n",
    "1. Narrow down important features to help gain intuition or improve model performance (more generalised model?)\n",
    "2. Play round with sampling methods and discover impact\n",
    "3. Explore other feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lst.remove('Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation matrix\n",
    "Because this data is heavily unbalanced, the usual accuracy metrix is not suitable. Alternatively we use the area under the Precision-Recall curve to evaluate our model. The reason is because there is a very small group of positive(fraud) cases, to accurally and sensitively measure the model performance, TN(True negative) is too large to be included. Hence precision and recall are more useful. <br>\n",
    "Here we are not trying to decide whether precision or recall is more important. Imagine a bank would want to achieve high precision: true positive/(true positive + false positive), less false alarm AND high recall: true positive/(true positive + false negative), less undetected fraud.<br>\n",
    "The calculation of the AUC of PR curve is included in the metrics.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic logistic model with over and under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "exog = sm.add_constant(X[features_lst])\n",
    "endog = X['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_mod = sm.Logit(endog=endog, exog=exog)\n",
    "log_res = logit_mod.fit(method='bfgs', maxiter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn and Statsmodel different results under 'bfgs' solver?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete quasi-separation** <br>\n",
    "For a visual understanding of quasi-separation, read here: <br>\n",
    "https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/regression-models/what-are-complete-separation-and-quasi-complete-separation/ <br>\n",
    "\n",
    "A possible complete quasi-separation perhaps indicate that some of the features yield perfect prediction for most values, but not all. Looking back at the pairplot produced between unknow features, V9-V20 definitely exhibit some of that characteristics. <br>\n",
    "\n",
    "(Unvarified due to time limit) Some suggested that features with insignificant results with big coefficients and huge confidence intervals suggest they contribute to quasi-separation <br>\n",
    "\n",
    "The logistic does produce high sudo R-sq score. However we will have a look at PR-AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = log_res.predict(exog=exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, make_scorer\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "def pr_auc(y, y_pred):\n",
    "    # calculate the area under the precision recall curve\n",
    "    p, r, _ = precision_recall_curve(y, y_pred)\n",
    "    return auc(r, p)\n",
    "\n",
    "def evaluate_model(X, y, model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    metric = make_scorer(pr_auc, needs_proba=True)\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Stochastic Average Gradient descent solver\n",
    "model = LogisticRegression(fit_intercept=False, solver='lbfgs', max_iter=1000)\n",
    "scores = evaluate_model(X[features_lst], X['fraud'], model)\n",
    "print('Mean AUC score:{}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite a good score!<br>\n",
    "We could reduce the features based on the statsmodel output, but we will keep them as they are.<br>\n",
    "We wrap up EDA with a summary of preprocessing steps, as below. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def preproc(df):\n",
    "\n",
    "    df['timedelta'] = df['Time'].apply(lambda x: datetime.timedelta(seconds=x))\n",
    "    df['fraud'] = df['Class'].astype('category')\n",
    "    df.sort_values('Time', inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df['hour'] = (df['Time']//3600).astype('int')\n",
    "    df['hour'] = [hour if hour <= 23 else hour-24 for hour in list(df['hour'])]\n",
    "    df['hour'] = df['hour'].astype('category')\n",
    "    unkwn_features = ['V{}'.format(n+1) for n in range(0, 28)]\n",
    "\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    df['Amount'] = np.squeeze(scaler.fit_transform(\n",
    "        np.array(df['Amount']).reshape(-1, 1)))\n",
    "    df.rename(columns={'fraud_1': 'fraud'}, inplace=True)\n",
    "    features_lst = ['Amount'] + unkwn_features + \\\n",
    "        ['hour_{}'.format(i) for i in range(1, 24)]\n",
    "    X = df[features_lst]\n",
    "    y = df['fraud']\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def sampler(X, y, over_pct, under_pct):\n",
    "    over = SMOTE(random_state=42, sampling_strategy=over_pct)\n",
    "    under = RandomUnderSampler(random_state=42, sampling_strategy=under_pct)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X, y = pipeline.fit_resample(X, y)\n",
    "    return X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
